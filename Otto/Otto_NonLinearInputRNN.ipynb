{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import os\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "seq_length = 800\n",
    "merge_factor = 4#temporal resolution = merge_factor/16000 #discrimination_window = merge_factor*seq_length/16000\n",
    "n_train = 180; n_test = 180;\n",
    "num_channels = 2\n",
    "input_size = num_channels*merge_factor #n_channels*merge_factor\n",
    "num_classes = 5 #n_directions\n",
    "offset = 64\n",
    "train_x = []; train_t = []\n",
    "test_x = []; test_t = []\n",
    "for i in range(num_classes):\n",
    "    angle = 0+(45*i)\n",
    "    temp_data = scipy.io.wavfile.read('speech2/'+'d'+str(angle)+'.wav')[1][:]\n",
    "    for j in range(n_train+n_test):\n",
    "        if j%2 != 1:\n",
    "            train_x.append(temp_data[offset+(j*seq_length*merge_factor):offset+((j+1)*seq_length*merge_factor)])\n",
    "            train_t.append(i)\n",
    "    #for j in range(n_train,n_train+n_test):\n",
    "        else:\n",
    "            test_x.append(temp_data[offset+(j*seq_length*merge_factor):offset+((j+1)*seq_length*merge_factor)])\n",
    "            test_t.append(i)\n",
    "\n",
    "train_x = np.array(train_x); train_t = np.array(train_t)\n",
    "train_x = train_x.reshape(n_train*num_classes,seq_length,input_size)\n",
    "test_x = np.array(test_x); test_t = np.array(test_t)\n",
    "test_x = test_x.reshape(n_test*num_classes,seq_length,input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "x = tf.placeholder(tf.float32, [None,seq_length, input_size])\n",
    "labels = tf.placeholder(tf.int32, [None])\n",
    "i_size = 40\n",
    "h_size = 40\n",
    "g_size = 40\n",
    "learning_rate = tf.placeholder(tf.float32,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "# r_i = np.sqrt(6.0/(input_size + context_size))\n",
    "# r_c = np.sqrt(6.0/(context_size + context_size))\n",
    "# r_y = np.sqrt(6.0/(context_size + num_classes))\n",
    "sdev = 0.1   \n",
    "params = {\n",
    "    'Wxi': tf.Variable(tf.random_normal([input_size, i_size],stddev=sdev)),\n",
    "    'Wih': tf.Variable(tf.random_normal([i_size,h_size],stddev=sdev)),\n",
    "    'Whg': tf.Variable(tf.random_normal([h_size, g_size],stddev = sdev)),\n",
    "    'Wgg': tf.Variable(tf.random_normal([g_size, g_size],stddev = sdev)), #initial_value=tf.cast(np.eye(g_size),dtype=tf.float32)\n",
    "    'Wgy': tf.Variable(tf.random_normal([g_size,num_classes],stddev = sdev)),\n",
    "    'bi': tf.Variable(tf.zeros([i_size])),\n",
    "    'bh': tf.Variable(tf.zeros([h_size])),\n",
    "    'bg': tf.Variable(tf.zeros([g_size])),\n",
    "    'by': tf.Variable(tf.zeros([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# architecture\n",
    "def RNN(x,params):\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    g = tf.zeros([batch_size,g_size])\n",
    "    for t in range(seq_length):\n",
    "        i = tf.tanh(tf.add(tf.matmul(x[:,t,:],params['Wxi']),params['bi']))\n",
    "        h = tf.tanh(tf.add(tf.matmul(i,params['Wih']),params['bh']))\n",
    "        g = tf.tanh(tf.add(tf.add(tf.matmul(g,params['Wgg']),tf.matmul(h,params['Whg'])),params['bg']))\n",
    "    y = tf.add(tf.matmul(g,params['Wgy']),params['by'])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training strategy\n",
    "y = RNN(x,params)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y,labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(cost)\n",
    "capped_grads_and_vars = [(tf.clip_by_value(gv[0],-1.,1.), gv[1]) for gv in grads_and_vars]\n",
    "capped_optimizer = optimizer.apply_gradients(capped_grads_and_vars)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0 cost:0.885075\n",
      "train pf = 0.693333333333\n",
      "test pf = 0.228888888889\n",
      "\n",
      "iter1 cost:0.857339\n",
      "iter2 cost:0.838114\n",
      "iter3 cost:0.834426\n",
      "iter4 cost:0.828988\n",
      "iter5 cost:0.821341\n",
      "iter6 cost:0.816901\n",
      "iter7 cost:0.816618\n",
      "iter8 cost:0.81227\n",
      "iter9 cost:0.809235\n",
      "iter10 cost:0.806966\n",
      "iter11 cost:0.804642\n",
      "iter12 cost:0.800788\n",
      "iter13 cost:0.797357\n",
      "iter14 cost:0.796251\n",
      "iter15 cost:0.795851\n",
      "iter16 cost:0.793312\n",
      "iter17 cost:0.79248\n",
      "iter18 cost:0.795659\n",
      "iter19 cost:0.791253\n",
      "iter20 cost:0.789797\n",
      "train pf = 0.731111111111\n",
      "test pf = 0.233333333333\n",
      "\n",
      "iter21 cost:0.790303\n",
      "iter22 cost:0.788218\n",
      "iter23 cost:0.784712\n",
      "iter24 cost:0.787817\n",
      "iter25 cost:0.787184\n",
      "iter26 cost:0.787239\n",
      "iter27 cost:0.784208\n",
      "iter28 cost:0.779648\n",
      "iter29 cost:0.777028\n",
      "iter30 cost:0.777102\n",
      "iter31 cost:0.788015\n",
      "iter32 cost:0.777032\n",
      "iter33 cost:0.776093\n",
      "iter34 cost:0.770755\n",
      "iter35 cost:0.76636\n",
      "iter36 cost:0.766998\n",
      "iter37 cost:0.766042\n",
      "iter38 cost:0.762144\n",
      "iter39 cost:0.761424\n",
      "iter40 cost:0.761771\n",
      "train pf = 0.751111111111\n",
      "test pf = 0.232222222222\n",
      "\n",
      "iter41 cost:0.761685\n",
      "iter42 cost:0.759482\n",
      "iter43 cost:0.760034\n",
      "iter44 cost:0.756429\n",
      "iter45 cost:0.752618\n",
      "iter46 cost:0.752868\n",
      "iter47 cost:0.748745\n",
      "iter48 cost:0.747232\n",
      "iter49 cost:0.746962\n",
      "iter50 cost:0.746264\n",
      "iter51 cost:0.754074\n",
      "iter52 cost:0.750967\n",
      "iter53 cost:0.752367\n",
      "iter54 cost:0.754907\n",
      "iter55 cost:0.74625\n",
      "iter56 cost:0.747634\n",
      "iter57 cost:0.740543\n",
      "iter58 cost:0.73953\n",
      "iter59 cost:0.739895\n",
      "iter60 cost:0.736647\n",
      "train pf = 0.751111111111\n",
      "test pf = 0.243333333333\n",
      "\n",
      "iter61 cost:0.733787\n",
      "iter62 cost:0.73654\n",
      "iter63 cost:0.732424\n",
      "iter64 cost:0.729709\n",
      "iter65 cost:0.733468\n",
      "iter66 cost:0.728986\n",
      "iter67 cost:0.728111\n",
      "iter68 cost:0.729763\n",
      "iter69 cost:0.725951\n",
      "iter70 cost:0.728515\n",
      "iter71 cost:0.728175\n",
      "iter72 cost:0.724757\n",
      "iter73 cost:0.726632\n",
      "iter74 cost:0.718654\n",
      "iter75 cost:0.72356\n",
      "iter76 cost:0.719883\n",
      "iter77 cost:0.718454\n",
      "iter78 cost:0.719608\n",
      "iter79 cost:0.714292\n",
      "iter80 cost:0.71559\n",
      "train pf = 0.758888888889\n",
      "test pf = 0.242222222222\n",
      "\n",
      "iter81 cost:0.716123\n",
      "iter82 cost:0.713575\n",
      "iter83 cost:0.714442\n",
      "iter84 cost:0.709905\n",
      "iter85 cost:0.710331\n",
      "iter86 cost:0.704635\n",
      "iter87 cost:0.705613\n",
      "iter88 cost:0.708507\n",
      "iter89 cost:0.707401\n",
      "iter90 cost:0.703804\n",
      "iter91 cost:0.701707\n",
      "iter92 cost:0.70511\n",
      "iter93 cost:0.69629\n",
      "iter94 cost:0.700113\n",
      "iter95 cost:0.704968\n",
      "iter96 cost:0.698816\n",
      "iter97 cost:0.697881\n",
      "iter98 cost:0.695121\n",
      "iter99 cost:0.693565\n",
      "iter100 cost:0.694693\n",
      "train pf = 0.761111111111\n",
      "test pf = 0.237777777778\n",
      "\n",
      "iter101 cost:0.698433\n",
      "iter102 cost:0.697873\n",
      "iter103 cost:0.701015\n",
      "iter104 cost:0.695778\n",
      "iter105 cost:0.691096\n",
      "iter106 cost:0.693423\n",
      "iter107 cost:0.698157\n",
      "iter108 cost:0.694345\n",
      "iter109 cost:0.692746\n",
      "iter110 cost:0.703549\n",
      "iter111 cost:0.700136\n",
      "iter112 cost:0.697305\n",
      "iter113 cost:0.697437\n",
      "iter114 cost:0.693311\n",
      "iter115 cost:0.689748\n",
      "iter116 cost:0.683659\n",
      "iter117 cost:0.696854\n",
      "iter118 cost:0.695217\n",
      "iter119 cost:0.689359\n",
      "iter120 cost:0.694936\n",
      "train pf = 0.776666666667\n",
      "test pf = 0.231111111111\n",
      "\n",
      "iter121 cost:0.69173\n",
      "iter122 cost:0.690869\n",
      "iter123 cost:0.685632\n",
      "iter124 cost:0.682636\n",
      "iter125 cost:0.681713\n",
      "iter126 cost:0.679361\n",
      "iter127 cost:0.677977\n",
      "iter128 cost:0.676547\n",
      "iter129 cost:0.683365\n",
      "iter130 cost:0.68838\n",
      "iter131 cost:0.675961\n",
      "iter132 cost:0.684756\n",
      "iter133 cost:0.688663\n",
      "iter134 cost:0.678782\n",
      "iter135 cost:0.67618\n",
      "iter136 cost:0.677662\n",
      "iter137 cost:0.676988\n",
      "iter138 cost:0.678506\n",
      "iter139 cost:0.675073\n",
      "iter140 cost:0.675803\n",
      "train pf = 0.78\n",
      "test pf = 0.222222222222\n",
      "\n",
      "iter141 cost:0.671113\n",
      "iter142 cost:0.671685\n",
      "iter143 cost:0.673022\n",
      "iter144 cost:0.669702\n",
      "iter145 cost:0.675933\n",
      "iter146 cost:0.675636\n",
      "iter147 cost:0.711713\n",
      "iter148 cost:0.678054\n",
      "iter149 cost:0.676926\n",
      "iter150 cost:0.673224\n",
      "iter151 cost:0.677771\n",
      "iter152 cost:0.669778\n",
      "iter153 cost:0.675586\n",
      "iter154 cost:0.672747\n",
      "iter155 cost:0.6735\n",
      "iter156 cost:0.669678\n",
      "iter157 cost:0.673079\n",
      "iter158 cost:0.664789\n",
      "iter159 cost:0.672092\n",
      "iter160 cost:0.670368\n",
      "train pf = 0.79\n",
      "test pf = 0.236666666667\n",
      "\n",
      "iter161 cost:0.66322\n",
      "iter162 cost:0.657498\n",
      "iter163 cost:0.65821\n",
      "iter164 cost:0.655873\n",
      "iter165 cost:0.65243\n",
      "iter166 cost:0.652593\n",
      "iter167 cost:0.653078\n",
      "iter168 cost:0.662004\n",
      "iter169 cost:0.669933\n",
      "iter170 cost:0.666052\n",
      "iter171 cost:0.658993\n",
      "iter172 cost:0.670565\n",
      "iter173 cost:0.655184\n",
      "iter174 cost:0.654103\n",
      "iter175 cost:0.66794\n",
      "iter176 cost:0.664823\n",
      "iter177 cost:0.655269\n",
      "iter178 cost:0.657937\n",
      "iter179 cost:0.658481\n",
      "iter180 cost:0.662734\n",
      "train pf = 0.782222222222\n",
      "test pf = 0.238888888889\n",
      "\n",
      "iter181 cost:0.65785\n",
      "iter182 cost:0.659311\n",
      "iter183 cost:0.654391\n",
      "iter184 cost:0.647686\n",
      "iter185 cost:0.647183\n",
      "iter186 cost:0.655313\n",
      "iter187 cost:0.648184\n",
      "iter188 cost:0.657498\n",
      "iter189 cost:0.647579\n",
      "iter190 cost:0.652054\n",
      "iter191 cost:0.642908\n",
      "iter192 cost:0.649188\n",
      "iter193 cost:0.656747\n",
      "iter194 cost:0.658957\n",
      "iter195 cost:0.652288\n",
      "iter196 cost:0.668037\n",
      "iter197 cost:0.661198\n",
      "iter198 cost:0.679433\n",
      "iter199 cost:0.658737\n",
      "iter200 cost:0.645715\n",
      "train pf = 0.801111111111\n",
      "test pf = 0.238888888889\n",
      "\n",
      "iter201 cost:0.640491\n",
      "iter202 cost:0.639717\n",
      "iter203 cost:0.641604\n",
      "iter204 cost:0.63941\n",
      "iter205 cost:0.639002\n",
      "iter206 cost:0.63195\n",
      "iter207 cost:0.635656\n",
      "iter208 cost:0.635303\n",
      "iter209 cost:0.633079\n",
      "iter210 cost:0.639721\n",
      "iter211 cost:0.636715\n",
      "iter212 cost:0.635802\n",
      "iter213 cost:0.630068\n",
      "iter214 cost:0.630208\n",
      "iter215 cost:0.628623\n",
      "iter216 cost:0.637639\n",
      "iter217 cost:0.671327\n",
      "iter218 cost:0.652294\n",
      "iter219 cost:0.662092\n",
      "iter220 cost:0.643634\n",
      "train pf = 0.781111111111\n",
      "test pf = 0.233333333333\n",
      "\n",
      "iter221 cost:0.659099\n",
      "iter222 cost:0.633122\n",
      "iter223 cost:0.630323\n",
      "iter224 cost:0.628335\n",
      "iter225 cost:0.63172\n",
      "iter226 cost:0.636093\n",
      "iter227 cost:0.63768\n",
      "iter228 cost:0.635852\n",
      "iter229 cost:0.637538\n",
      "iter230 cost:0.636012\n",
      "iter231 cost:0.636349\n",
      "iter232 cost:0.638185\n",
      "iter233 cost:0.641846\n",
      "iter234 cost:0.638294\n",
      "iter235 cost:0.62652\n",
      "iter236 cost:0.621424\n",
      "iter237 cost:0.618981\n",
      "iter238 cost:0.620036\n",
      "iter239 cost:0.616023\n",
      "iter240 cost:0.617462\n",
      "train pf = 0.807777777778\n",
      "test pf = 0.218888888889\n",
      "\n",
      "iter241 cost:0.623372\n",
      "iter242 cost:0.656231\n",
      "iter243 cost:0.627767\n",
      "iter244 cost:0.622056\n",
      "iter245 cost:0.61555\n",
      "iter246 cost:0.61561\n",
      "iter247 cost:0.660055\n",
      "iter248 cost:0.629175\n",
      "iter249 cost:0.612232\n",
      "iter250 cost:0.609201\n",
      "iter251 cost:0.624447\n",
      "iter252 cost:0.621745\n",
      "iter253 cost:0.632773\n",
      "iter254 cost:0.647011\n",
      "iter255 cost:0.623364\n",
      "iter256 cost:0.626063\n",
      "iter257 cost:0.628867\n",
      "iter258 cost:0.642442\n",
      "iter259 cost:0.644968\n",
      "iter260 cost:0.621828\n",
      "train pf = 0.815555555556\n",
      "test pf = 0.228888888889\n",
      "\n",
      "iter261 cost:0.61666\n",
      "iter262 cost:0.602787\n",
      "iter263 cost:0.638653\n",
      "iter264 cost:0.649407\n",
      "iter265 cost:0.654312\n",
      "iter266 cost:0.6417\n",
      "iter267 cost:0.624053\n",
      "iter268 cost:0.624534\n",
      "iter269 cost:0.636142\n",
      "iter270 cost:0.620949\n",
      "iter271 cost:0.610106\n",
      "iter272 cost:0.611567\n",
      "iter273 cost:0.605733\n",
      "iter274 cost:1.11739\n",
      "iter275 cost:0.935933\n",
      "iter276 cost:0.77368\n",
      "iter277 cost:0.698434\n",
      "iter278 cost:0.650858\n",
      "iter279 cost:0.627433\n",
      "iter280 cost:0.617449\n",
      "train pf = 0.81\n",
      "test pf = 0.225555555556\n",
      "\n",
      "iter281 cost:0.619621\n",
      "iter282 cost:0.625767\n",
      "iter283 cost:0.626553\n",
      "iter284 cost:0.622527\n",
      "iter285 cost:0.625029\n",
      "iter286 cost:0.616218\n",
      "iter287 cost:0.62633\n",
      "iter288 cost:0.620427\n",
      "iter289 cost:0.614292\n",
      "iter290 cost:0.594471\n",
      "iter291 cost:0.594531\n",
      "iter292 cost:0.597783\n",
      "iter293 cost:0.599416\n",
      "iter294 cost:0.604507\n",
      "iter295 cost:0.618321\n",
      "iter296 cost:0.628399\n",
      "iter297 cost:0.619377\n",
      "iter298 cost:0.643879\n",
      "iter299 cost:0.659056\n",
      "iter300 cost:0.628353\n",
      "train pf = 0.801111111111\n",
      "test pf = 0.228888888889\n",
      "\n",
      "iter301 cost:0.615957\n",
      "iter302 cost:0.604608\n",
      "iter303 cost:0.612646\n",
      "iter304 cost:0.605634\n",
      "iter305 cost:0.599475\n",
      "iter306 cost:0.606702\n",
      "iter307 cost:0.599375\n",
      "iter308 cost:0.601752\n",
      "iter309 cost:0.754106\n",
      "iter310 cost:0.6399\n",
      "iter311 cost:0.601389\n",
      "iter312 cost:0.588346\n",
      "iter313 cost:0.584471\n",
      "iter314 cost:0.579722\n",
      "iter315 cost:0.579424\n",
      "iter316 cost:0.582715\n",
      "iter317 cost:0.582343\n",
      "iter318 cost:0.635225\n",
      "iter319 cost:0.642766\n",
      "iter320 cost:0.602248\n",
      "train pf = 0.762222222222\n",
      "test pf = 0.227777777778\n",
      "\n",
      "iter321 cost:0.690834\n",
      "iter322 cost:0.605852\n",
      "iter323 cost:0.596375\n",
      "iter324 cost:0.60811\n",
      "iter325 cost:0.589943\n",
      "iter326 cost:0.587911\n",
      "iter327 cost:0.578161\n",
      "iter328 cost:0.591138\n",
      "iter329 cost:0.584953\n",
      "iter330 cost:0.576202\n",
      "iter331 cost:0.590361\n",
      "iter332 cost:0.658781\n",
      "iter333 cost:0.57786\n",
      "iter334 cost:0.576429\n",
      "iter335 cost:0.573994\n",
      "iter336 cost:0.5692\n",
      "iter337 cost:0.57272\n",
      "iter338 cost:0.567539\n",
      "iter339 cost:0.564188\n",
      "iter340 cost:0.564182\n",
      "train pf = 0.841111111111\n",
      "test pf = 0.224444444444\n",
      "\n",
      "iter341 cost:0.566718\n",
      "iter342 cost:0.572256\n",
      "iter343 cost:0.560955\n",
      "iter344 cost:0.557791\n",
      "iter345 cost:0.561458\n",
      "iter346 cost:0.570914\n",
      "iter347 cost:0.583736\n",
      "iter348 cost:0.573319\n",
      "iter349 cost:0.569682\n",
      "iter350 cost:0.567504\n",
      "iter351 cost:0.567522\n",
      "iter352 cost:0.564361\n",
      "iter353 cost:0.572172\n",
      "iter354 cost:0.580047\n",
      "iter355 cost:0.644542\n",
      "iter356 cost:0.571799\n",
      "iter357 cost:0.576014\n",
      "iter358 cost:0.595164\n",
      "iter359 cost:0.583258\n",
      "iter360 cost:0.584294\n",
      "train pf = 0.833333333333\n",
      "test pf = 0.225555555556\n",
      "\n",
      "iter361 cost:0.580765\n",
      "iter362 cost:0.585031\n",
      "iter363 cost:0.572758\n",
      "iter364 cost:0.572045\n",
      "iter365 cost:0.571929\n",
      "iter366 cost:0.560578\n",
      "iter367 cost:0.561576\n",
      "iter368 cost:0.561321\n",
      "iter369 cost:0.57765\n",
      "iter370 cost:0.558441\n",
      "iter371 cost:0.552233\n",
      "iter372 cost:0.549803\n",
      "iter373 cost:0.565951\n",
      "iter374 cost:0.563755\n",
      "iter375 cost:0.573213\n",
      "iter376 cost:0.568914\n",
      "iter377 cost:0.568198\n",
      "iter378 cost:0.568686\n",
      "iter379 cost:0.56956\n",
      "iter380 cost:0.559426\n",
      "train pf = 0.828888888889\n",
      "test pf = 0.214444444444\n",
      "\n",
      "iter381 cost:0.601547\n",
      "iter382 cost:0.626852\n",
      "iter383 cost:0.582739\n",
      "iter384 cost:0.617208\n",
      "iter385 cost:0.580398\n",
      "iter386 cost:0.586046\n",
      "iter387 cost:0.576156\n",
      "iter388 cost:0.592065\n",
      "iter389 cost:0.577005\n",
      "iter390 cost:0.56396\n",
      "iter391 cost:0.571122\n",
      "iter392 cost:0.563104\n",
      "iter393 cost:0.582276\n",
      "iter394 cost:0.56573\n",
      "iter395 cost:0.563091\n",
      "iter396 cost:0.569648\n",
      "iter397 cost:0.626031\n",
      "iter398 cost:0.663721\n",
      "iter399 cost:0.579674\n",
      "iter400 cost:0.565773\n",
      "train pf = 0.846666666667\n",
      "test pf = 0.23\n",
      "\n",
      "iter401 cost:0.567464\n",
      "iter402 cost:0.56891\n",
      "iter403 cost:0.567145\n",
      "iter404 cost:0.56512\n",
      "iter405 cost:0.564281\n",
      "iter406 cost:0.574713\n",
      "iter407 cost:0.619086\n",
      "iter408 cost:0.605001\n",
      "iter409 cost:0.625484\n",
      "iter410 cost:0.615636\n",
      "iter411 cost:0.597812\n",
      "iter412 cost:0.619727\n",
      "iter413 cost:0.595856\n",
      "iter414 cost:0.588182\n",
      "iter415 cost:0.58494\n",
      "iter416 cost:0.587053\n",
      "iter417 cost:0.569865\n",
      "iter418 cost:0.567004\n",
      "iter419 cost:0.587313\n",
      "iter420 cost:0.580079\n",
      "train pf = 0.81\n",
      "test pf = 0.245555555556\n",
      "\n",
      "iter421 cost:0.590824\n",
      "iter422 cost:0.655561\n",
      "iter423 cost:0.667542\n",
      "iter424 cost:0.569734\n",
      "iter425 cost:0.570823\n",
      "iter426 cost:0.588689\n",
      "iter427 cost:0.568618\n",
      "iter428 cost:0.567595\n",
      "iter429 cost:0.566505\n",
      "iter430 cost:0.564858\n",
      "iter431 cost:0.583862\n",
      "iter432 cost:0.578539\n",
      "iter433 cost:0.559777\n",
      "iter434 cost:0.560594\n",
      "iter435 cost:0.546865\n",
      "iter436 cost:0.551959\n",
      "iter437 cost:0.554635\n",
      "iter438 cost:0.576373\n",
      "iter439 cost:0.574415\n",
      "iter440 cost:0.602388\n",
      "train pf = 0.834444444444\n",
      "test pf = 0.228888888889\n",
      "\n",
      "iter441 cost:0.570828\n",
      "iter442 cost:0.583657\n",
      "iter443 cost:0.588396\n",
      "iter444 cost:0.555334\n",
      "iter445 cost:0.557825\n",
      "iter446 cost:0.548102\n",
      "iter447 cost:0.550074\n",
      "iter448 cost:0.541111\n",
      "iter449 cost:0.545159\n",
      "iter450 cost:0.567878\n",
      "iter451 cost:0.579465\n",
      "iter452 cost:0.572791\n",
      "iter453 cost:0.555437\n",
      "iter454 cost:0.547969\n",
      "iter455 cost:0.561116\n",
      "iter456 cost:0.57139\n",
      "iter457 cost:0.57868\n",
      "iter458 cost:0.597358\n",
      "iter459 cost:0.565046\n",
      "iter460 cost:0.564542\n",
      "train pf = 0.856666666667\n",
      "test pf = 0.221111111111\n",
      "\n",
      "iter461 cost:0.547269\n",
      "iter462 cost:0.544751\n",
      "iter463 cost:0.531979\n",
      "iter464 cost:0.528751\n",
      "iter465 cost:0.532112\n",
      "iter466 cost:0.524351\n",
      "iter467 cost:0.529504\n",
      "iter468 cost:0.531681\n",
      "iter469 cost:0.522265\n",
      "iter470 cost:0.515497\n",
      "iter471 cost:0.51374\n",
      "iter472 cost:0.520026\n",
      "iter473 cost:0.515921\n",
      "iter474 cost:0.521301\n",
      "iter475 cost:0.51828\n",
      "iter476 cost:0.520368\n",
      "iter477 cost:0.537272\n",
      "iter478 cost:0.531751\n",
      "iter479 cost:0.542123\n",
      "iter480 cost:0.532692\n",
      "train pf = 0.857777777778\n",
      "test pf = 0.227777777778\n",
      "\n",
      "iter481 cost:0.535312\n",
      "iter482 cost:0.57104\n",
      "iter483 cost:0.561511\n",
      "iter484 cost:0.610124\n",
      "iter485 cost:0.549226\n",
      "iter486 cost:0.564688\n",
      "iter487 cost:0.539934\n",
      "iter488 cost:0.565152\n",
      "iter489 cost:0.550703\n",
      "iter490 cost:0.53998\n",
      "iter491 cost:0.557804\n",
      "iter492 cost:0.556762\n",
      "iter493 cost:0.562477\n",
      "iter494 cost:0.575447\n",
      "iter495 cost:0.564974\n",
      "iter496 cost:0.542337\n",
      "iter497 cost:0.539318\n",
      "iter498 cost:0.560026\n",
      "iter499 cost:0.591261\n",
      "iter500 cost:0.614965\n",
      "train pf = 0.828888888889\n",
      "test pf = 0.211111111111\n",
      "\n",
      "iter501 cost:0.566879\n",
      "iter502 cost:0.56285\n",
      "iter503 cost:0.555322\n",
      "iter504 cost:0.544837\n",
      "iter505 cost:0.541877\n",
      "iter506 cost:0.540877\n",
      "iter507 cost:0.541614\n",
      "iter508 cost:0.606538\n",
      "iter509 cost:0.583421\n",
      "iter510 cost:0.638011\n",
      "iter511 cost:0.568184\n",
      "iter512 cost:0.584561\n",
      "iter513 cost:0.559242\n",
      "iter514 cost:0.570682\n",
      "iter515 cost:0.553519\n",
      "iter516 cost:0.539226\n",
      "iter517 cost:0.554729\n",
      "iter518 cost:0.560497\n",
      "iter519 cost:0.551776\n",
      "iter520 cost:0.553304\n",
      "train pf = 0.852222222222\n",
      "test pf = 0.223333333333\n",
      "\n",
      "iter521 cost:0.530243\n",
      "iter522 cost:0.52466\n",
      "iter523 cost:0.519992\n",
      "iter524 cost:0.544964\n",
      "iter525 cost:0.607295\n",
      "iter526 cost:1.1374\n",
      "iter527 cost:0.96501\n",
      "iter528 cost:0.866877\n",
      "iter529 cost:0.817832\n",
      "iter530 cost:0.75908\n",
      "iter531 cost:0.722511\n",
      "iter532 cost:0.679083\n",
      "iter533 cost:0.642584\n",
      "iter534 cost:0.616549\n",
      "iter535 cost:0.605452\n",
      "iter536 cost:0.60869\n",
      "iter537 cost:0.604481\n",
      "iter538 cost:0.590859\n",
      "iter539 cost:0.610564\n",
      "iter540 cost:0.586334\n",
      "train pf = 0.815555555556\n",
      "test pf = 0.228888888889\n",
      "\n",
      "iter541 cost:0.607562\n",
      "iter542 cost:0.56707\n",
      "iter543 cost:0.566834\n",
      "iter544 cost:0.566377\n",
      "iter545 cost:0.595229\n",
      "iter546 cost:0.609106\n",
      "iter547 cost:0.575279\n",
      "iter548 cost:0.562569\n",
      "iter549 cost:0.549957\n",
      "iter550 cost:0.556541\n",
      "iter551 cost:0.558712\n",
      "iter552 cost:0.553132\n",
      "iter553 cost:0.553128\n",
      "iter554 cost:0.575643\n",
      "iter555 cost:0.559359\n",
      "iter556 cost:0.572673\n",
      "iter557 cost:0.563706\n",
      "iter558 cost:0.575551\n",
      "iter559 cost:0.589545\n",
      "iter560 cost:0.601219\n",
      "train pf = 0.815555555556\n",
      "test pf = 0.23\n",
      "\n",
      "iter561 cost:0.596321\n",
      "iter562 cost:0.590688\n",
      "iter563 cost:0.565215\n",
      "iter564 cost:0.557034\n",
      "iter565 cost:0.559398\n",
      "iter566 cost:0.565077\n",
      "iter567 cost:0.560545\n",
      "iter568 cost:0.659904\n",
      "iter569 cost:1.76153\n",
      "iter570 cost:2.1276\n",
      "iter571 cost:2.49025\n",
      "iter572 cost:2.13598\n",
      "iter573 cost:2.0538\n",
      "iter574 cost:1.99857\n",
      "iter575 cost:1.94498\n",
      "iter576 cost:1.89153\n",
      "iter577 cost:1.8459\n",
      "iter578 cost:1.80626\n",
      "iter579 cost:1.7672\n",
      "iter580 cost:1.73498\n",
      "train pf = 0.365555555556\n",
      "test pf = 0.226666666667\n",
      "\n",
      "iter581 cost:1.70867\n",
      "iter582 cost:1.68323\n",
      "iter583 cost:1.65932\n",
      "iter584 cost:1.63788\n",
      "iter585 cost:1.6174\n",
      "iter586 cost:1.59811\n",
      "iter587 cost:1.57931\n",
      "iter588 cost:1.56249\n",
      "iter589 cost:1.54679\n",
      "iter590 cost:1.5311\n",
      "iter591 cost:1.51744\n",
      "iter592 cost:1.50425\n",
      "iter593 cost:1.49024\n",
      "iter594 cost:1.47681\n",
      "iter595 cost:1.46363\n",
      "iter596 cost:1.45052\n",
      "iter597 cost:1.43785\n",
      "iter598 cost:1.42486\n",
      "iter599 cost:1.41229\n",
      "iter600 cost:1.40024\n",
      "train pf = 0.442222222222\n",
      "test pf = 0.224444444444\n",
      "\n",
      "iter601 cost:1.38778\n",
      "iter602 cost:1.37697\n",
      "iter603 cost:1.36436\n",
      "iter604 cost:1.35519\n",
      "iter605 cost:1.34349\n",
      "iter606 cost:1.33697\n",
      "iter607 cost:1.32723\n",
      "iter608 cost:1.31782\n",
      "iter609 cost:1.30706\n",
      "iter610 cost:1.29761\n",
      "iter611 cost:1.28689\n",
      "iter612 cost:1.27339\n",
      "iter613 cost:1.261\n",
      "iter614 cost:1.24815\n",
      "iter615 cost:1.23103\n",
      "iter616 cost:1.21471\n",
      "iter617 cost:1.20268\n",
      "iter618 cost:1.18777\n",
      "iter619 cost:1.17362\n",
      "iter620 cost:1.16015\n",
      "train pf = 0.538888888889\n",
      "test pf = 0.221111111111\n",
      "\n",
      "iter621 cost:1.1513\n",
      "iter622 cost:1.13825\n",
      "iter623 cost:1.12608\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-45fa00cb88bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcapped_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iter'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' cost:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 372\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    373\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 636\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 708\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    709\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    713\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "while True:\n",
    "    _,cost_ = sess.run([capped_optimizer,cost],feed_dict={x:train_x,labels:train_t,learning_rate:0.01})\n",
    "    print('iter'+str(n_iter)+' cost:'+str(cost_))\n",
    "    if n_iter % 20 == 0:\n",
    "        y_train = sess.run(y,feed_dict={x:train_x})\n",
    "        print 'train pf = ' + str((sum(np.argmax(y_train,axis=1) == train_t) + 0.0)/(n_train*num_classes))\n",
    "        y_test = sess.run(y,feed_dict={x:test_x})\n",
    "        print 'test pf = ' + str((sum(np.argmax(y_test,axis=1) == test_t) + 0.0)/(n_test*num_classes))+'\\n'\n",
    "#         mypath = 'vars/iter'+str(n_iter)\n",
    "#         if not os.path.isdir(mypath):\n",
    "#            os.makedirs(mypath)\n",
    "#         myfile = mypath+'/'+str(n_iter)\n",
    "#         saver.save(sess,myfile,write_meta_graph=False)\n",
    "    n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 1 0 0 0 2 2 4 0 4 0 1 1 1 1 1 1 0 4 2 2 2 0 2 2 1 1 1 1 0 0 1 1 1 0 1\n",
      " 1 0 0 4 1 2 1 1 0 2 1 2 1 1 1 0 1 1 4 2 1 1 1 0 0 1 0 0 4 0 2 0 1 1 2 1 1\n",
      " 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 2 2 4 1 1 1 1 1 1 0 0\n",
      " 1 0 1 2 1 0 1 0 4 1 0 1 1 1 0 0 0 1 1 2 1 4 0 1 1 1 1 2 0 1 1 4 0 0 1 0 4\n",
      " 2 2 1 0 1 0 2 0 1 4 0 1 0 1 0 1 1 2 0 1 0 0 1 1 4 2 0 0 0 0 1 0 2 4 1 1 1\n",
      " 1 1 1 0 0 1 1 2 0 1 1 1 0 1 1 1 1 0 1 2 0 0 2 1 1 0 2 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 0 4 1 4 0 0 1 1 1 1 1 0 1 2 1 1 0 0 1 4 2 1 1 1 2 1 1 1 1 0 1 1\n",
      " 0 0 0 4 0 0 1 1 1 0 1 0 0 2 1 0 1 0 1 1 0 1 1 1 1 4 4 0 0 0 2 1 0 0 2 1 2\n",
      " 1 0 1 0 1 1 1 1 2 0 1 1 1 1 1 2 4 2 0 1 1 1 1 2 0 0 4 2 0 0 0 0 2 4 1 0 1\n",
      " 4 1 0 0 2 2 0 1 1 0 1 0 1 0 2 0 0 0 0 0 0 0 1 0 1 1 1 4 1 0 4 1 1 1 0 0 0\n",
      " 1 1 0 1 2 2 1 1 1 1 1 1 0 1 2 1 0 0 1 1 1 0 1 2 0 4 1 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 1 4 4 0 2 1 1 2 0 1 0 0 0 2 2 0 0 0 0 2 1 1 4 0 1 1 1 0 1 1 1 0 4 1 1\n",
      " 0 0 0 1 1 1 1 0 1 1 0 2 0 0 1 1 2 0 0 1 0 1 0 1 1 1 1 1 1 0 1 0 2 1 1 1 0\n",
      " 4 1 1 1 1 1 1 1 1 0 4 2 0 2 1 0 0 1 1 1 1 1 1 1 1 0 4 1 1 1 0 4 0 1 1 0 0\n",
      " 1 1 0 1 0 1 1 0 1 2 1 1 0 1 2 2 1 0 0 1 4 0 0 2 2 0 0 1 1 1 1 2 0 1 1 2 0\n",
      " 1 2 1 1 1 0 0 1 2 1 1 1 1 1 0 1 1 2 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0\n",
      " 0 0 1 4 0 1 1 1 1 1 1 1 1 0 2 2 0 1 1 1 0 4 1 1 2 0 1 1 1 1 2 1 0 1 1 1 2\n",
      " 0 4 0 0 0 0 0 0 2 0 0 2 0 1 0 0 1 1 2 0 1 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1\n",
      " 2 0 0 0 2 2 0 0 0 1 0 1 1 0 0 2 0 1 2 1 2 1 0 0 0 4 1 2 1 0 0 0 1 2 0 0 0\n",
      " 1 1 2 0 0 1 0 1 0 1 0 1 1 4 2 1 0 0 1 1 2 4 0 2 1 4 0 2 2 1 1 1 1 1 1 2 0\n",
      " 2 2 0 2 2 1 1 1 0 1 1 2 1 2 1 1 1 1 1 2 2 1 1 1 1 1 1 0 1 1 1 1 2 2 2 1 1\n",
      " 1 1 0 2 2 2 2 2 2 2 1 1 0 2 1 0 1 1 1 2 1 2 2 1 2 2 1 1 1 1 1 1 1 1 1 2 0\n",
      " 2 2 1 1 2 2 2 0 2 2 2 1 1 1 2 1 2 0 2 1 2 2 2 1 1 2 2 1 1 0 2 2 2 2 2 2 2\n",
      " 2 2 0 1 1 1 1 1 1 1 2 2 2 0 2 0 2 1 1 2 1 2 2 1 0 4 0 1 2 2 1 0 2 1 2 2 4\n",
      " 1 2 2 0 4 2 2 2 0 2 2 2 2 1 2 1 1 1 2 1 1 1 2 2 0 2 1 1 1 1 0 4 1 1 1 1 1\n",
      " 2 2 0 2 0 1 1 2 1 1 0 1 2 2 2 2 1 1 1 2 1 1 1 0 2 2 0 0 1 1 1 1 1 2 1 1 1\n",
      " 2 2 0 1 1 2 2 2 2 0 2 2 2 2 1 1 1 1 0 1 1 2 0 1 0 2 2 2 1 0 0 1 2 2 2 1 0\n",
      " 1 2 1 2 2 1 1 1 2 2 2 2 2 2 1 1 2 2 2 0 0 2 1 2 2 2 2 1 2 1 2 2 0 2 1 2 2\n",
      " 0 2 2 2 1 1 2 2 1 2 2 2 2 2 2 0 2 1 1 0 2 2 2 2 2 0 2 2 2 1 2 2 0 0 2 2 1\n",
      " 2 2 0 2 0 1 1 4 2 0 0 4 1 0 0 0 1 2 4 4 0 0 2 0 2 1 1 3 1 2 0 4 4 3 1 1 0\n",
      " 1 0 4 2 1 1 1 1 0 1 2 4 2 1 1 1 0 2 1 2 1 2 1 0 4 2 2 2 1 1 0 1 2 4 4 4 1\n",
      " 0 0 1 1 1 1 0 4 1 1 0 0 0 1 2 3 4 0 1 1 1 1 1 0 2 1 4 4 1 4 4 2 0 4 0 4 0\n",
      " 1 1 1 1 1 1 0 0 4 1 2 1 1 4 1 0 3 0 4 1 1 1 1 0 3 4 3 2 1 2 3 1 1 1 1 1 1\n",
      " 1 4 3 1 1 0 4 3 4 4 2 3 0 0 2 4 0 1 4 0 2 0 3 2 0 0 2 0 0 4 1 3 4 1 4 0 3\n",
      " 4 4 0 2 4 4 4 0 1 1 1 2 1 1 1 0 0 2 1 2 2 1 0 1 1 1 0 0 4 1 2 1 2 2 1 2 3\n",
      " 3 2 0 2 0 0 4 1 2 1 1 0 0 1 1 3 2 4 4 2 0 4 3 1 0 1 0 1 1 0 3 2 2 1 0 2 4\n",
      " 2 1 0 0 0 1 1 1 1 1 1 1 1 0 1 4 0 0 1 4 3 1 1 2 4 3 3 1 1 2 1 3 2 1 1 2 2\n",
      " 1 1 2 4 4 0 0 0 4 4 0 2 0 2 0 1 4 1 1 1 0 3 4 1 1 2 0 3 3 2 1 0 1 0 1 1 4\n",
      " 4 0 4 0 0 3 3 3 2 0 4 2 4 3 4 3 4 2 3 3 4 1 4 2 0 0 4 2 4 1 3 4 2 2 1 0 1\n",
      " 1 0 0 3 4 0 2 1 4 2 1 4 0 0 0 2 1 1 4 0 0 4 0 3 4 1 1 1 4 4 2 4 2 2 1 2 1\n",
      " 1 0 3 0 2 1 4 1 1 1 1 0 1 1 2 4 1 1 1 1 0 1 1 1 1 4 4 2 0 2 2 1 1 1 0 1 1\n",
      " 1 1 0 1 2 1 1 4 2 1 1 1 1 2 1 1 1 1 2 0 1 4 1 0 4 3 4 2 4 1 1 2 1 1 3 1 0\n",
      " 4 1 1 2 1 4 0 0 2 0 1 0 1 0 0 3 4 0 4 4 2 4 1 1 1 1 1 1 2 1 0 4 0 2 1 1 4\n",
      " 4 1 4 0 1 0 1 1 4 2 2 2 4 0 0 4 1 2 2 3 1 0 4 1 0 2 4 4 4 0 4 4 4 0 2 2 2\n",
      " 1 1 2 1 1 1 1 2 0 0 2 1 1 0 0 1 1 2 1 1 4 2 2 4 1 0 1 4 1 0 2 1 1 2 2 1 1\n",
      " 1 2 2 2 1 2 1 4 1 0 1 1 2 2 1 4 1 2 1 2 4 2 2 4 2 2 4 3 0 1 0 1 2 1 1 1 1\n",
      " 1 2 1 1 1 1 2 3 2 4 0 2 1 1 0 0 2 4 2 4 0 3 4 1 2 1 1 1 1 0 3 3 2 4 0 1 4\n",
      " 1 4 1 4 1 2 0 4 2 4 4 2 2 2 2 1 0 1 3 1 4 2 0 1 0 2 1 1 2 1 4 2 0 2 0 0 3\n",
      " 2 0 0 2 0 0 4 2 0 2 1 3 2 2 2 4 0 2 1 4 4 1 4 2]\n",
      "test pf = 0.308333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# new test data\n",
    "seq_length = 800\n",
    "merge_factor = 4#temporal resolution = merge_factor/16000 #discrimination_window = merge_factor*seq_length/16000\n",
    "n_test = 360;\n",
    "num_channels = 2\n",
    "input_size = num_channels*merge_factor #n_channels*merge_factor\n",
    "num_classes = 5 #n_directions\n",
    "offset = 64\n",
    "test_x = []; test_t = []\n",
    "for i in range(num_classes):\n",
    "    angle = 0+(45*i)\n",
    "    temp_data = scipy.io.wavfile.read('speech2/'+'d'+str(angle)+'.wav')[1]\n",
    "    #temp_data = scipy.io.wavfile.read('test.wav')[1]\n",
    "    for j in range(n_test):\n",
    "            test_x.append(temp_data[offset+(j*seq_length*merge_factor):offset+((j+1)*seq_length*merge_factor)])\n",
    "            test_t.append(i)\n",
    "\n",
    "test_x = np.array(test_x); test_t = np.array(test_t)\n",
    "test_x = test_x.reshape(n_test*num_classes,seq_length,input_size)\n",
    "y_test = sess.run(y,feed_dict={x:test_x})\n",
    "a = np.argmax(y_test,axis=1)\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print a\n",
    "print 'test pf = ' + str((sum(a == test_t) + 0.0)/(n_test*num_classes))+'\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.48005694  0.15055427  0.88199216  1.16462886  0.54344243 -1.10566723\n",
      "  -0.08513057 -1.08320999  0.34082413  0.7670604  -0.13694742 -0.15869716\n",
      "   0.28625828 -0.21132289 -0.03741002  1.24234259  1.05640435  0.13938001\n",
      "   0.25449252 -1.03470349 -0.09650949 -0.98656207 -0.20474197  0.26544335\n",
      "  -0.49741796 -0.69012272  0.49664998  1.30719697  0.0131028   0.32043955\n",
      "   0.73096704 -0.48393908 -1.33944154 -0.01340605  0.34093472 -0.94560033\n",
      "   0.27994648 -0.07995617 -0.34937885  0.10677422]\n",
      " [ 0.64371884  0.18987203  0.70021105  0.94224602  0.22143304 -0.92571706\n",
      "  -0.36325708  0.27240863 -0.83976859  0.71396554  0.27501214  0.85625666\n",
      "  -0.11009715  0.45200041  0.78372234  1.23681641 -0.31305283 -0.05921368\n",
      "   0.59527242 -0.49125737 -0.15702532 -0.11698069 -1.07355261  0.07230431\n",
      "  -0.41204128  0.0147009   0.70562679 -0.28617612 -0.30787349  0.05203527\n",
      "   0.55861336  0.6588034  -0.16618143 -0.90671206 -0.39303878 -0.96107173\n",
      "  -0.51395875  0.81070322  0.29636702  0.00724911]\n",
      " [ 0.70554715  0.94371945  0.29908875 -0.06077936  0.44472733 -0.5475229\n",
      "  -1.20069563 -0.48761651 -0.37066048  0.33279574 -0.24098092  0.17417185\n",
      "   0.55202812 -0.65916294  0.80448174  0.68048519  0.29666603  0.82045895\n",
      "   0.57734531  0.13098434 -0.14581664 -0.58735901  0.52232105  0.31083447\n",
      "  -0.85575289 -0.49319869  0.38435027  0.62342781 -0.65349656 -1.12911069\n",
      "  -0.29444799 -0.35840312 -0.03631397 -0.75266564  0.89891267 -0.46043438\n",
      "  -0.18028063  0.05050186 -0.76756316  0.18796539]\n",
      " [-0.20456927  0.14834125  0.43188411 -0.23543082 -0.75572222 -0.68983263\n",
      "   0.09468589 -0.1500975  -0.9823401  -0.13309701  0.49287507  0.3462635\n",
      "  -0.12096921  0.23041274  0.17480691  0.17534706 -0.6254316   0.12208586\n",
      "   0.55024588  0.14406726 -0.60047752 -0.95216674 -0.54321927  0.77336419\n",
      "   0.04026303 -1.49121881 -0.00759808  0.70525783 -0.09268952 -0.01736736\n",
      "   0.23493266  0.89920539 -0.36333913 -0.25407302 -0.51522768 -0.77416807\n",
      "  -0.28538668 -0.27925125 -0.50977391 -1.1736263 ]\n",
      " [ 0.60916048  0.74274272 -0.02588414  0.09837092  0.63423198  0.37802166\n",
      "  -0.64992458  0.9810217  -1.0162915  -0.19127019  0.18523377  0.86682844\n",
      "   0.38367957 -0.75947511  0.40884349  0.15423223 -0.48562449  0.79213482\n",
      "   0.44032001  0.68786705  0.46346581 -0.09399225  0.7156657  -0.29782173\n",
      "  -0.78880465  0.08475821  0.5985077  -0.67348635 -0.65030462 -1.29662097\n",
      "  -1.11620486  0.03473731 -0.80526048 -0.83222198  0.37165225  0.23815443\n",
      "   0.95584559 -0.0072937  -0.75793397  0.14502296]\n",
      " [-0.33962756 -0.03729926  0.06293452 -0.41174874 -1.05903947 -0.07311802\n",
      "   0.80781633 -0.07809836 -0.64596468  0.42391616  1.08829129 -0.46069238\n",
      "  -0.56111926 -0.65672368  0.15665029 -0.6203872  -0.75571442  0.7851854\n",
      "   0.3745482   0.10496585 -0.11644039 -0.18971559  0.42946696  0.47570556\n",
      "  -0.16953261 -0.47636274 -0.9537372   0.30291563  0.1203595  -1.14096284\n",
      "  -0.41932276  0.74199206 -0.42417383 -0.0801189  -1.04065895 -0.2128959\n",
      "   0.68891799 -1.29117918 -0.57233047 -0.8597014 ]\n",
      " [ 0.75225502  0.6643061   0.11807293  0.53570288  0.90535051 -0.03911176\n",
      "  -0.26416403  1.28051102  0.61539441 -0.5990724   0.46559176  0.86878628\n",
      "   0.02932929  0.07036196  0.12674327  0.23013099 -0.52728283  0.01475698\n",
      "  -0.08666215 -0.88084853  1.06573057 -0.33440459  0.09210403 -0.20552854\n",
      "   0.13558246 -0.30843028  0.65945226 -0.0317356  -0.09936174  0.28679094\n",
      "  -0.92671722  0.8410638  -1.15881395 -0.02469734  0.26631659  0.01354052\n",
      "   0.61410463 -0.69723821 -0.1121982  -0.08024134]\n",
      " [-0.24377322 -0.18447544  0.27295452 -0.01449735  0.48136991  0.41182694\n",
      "   0.66300905  0.23250543 -0.07396956  0.88347447  0.69291168 -0.06397425\n",
      "  -1.24961019  0.17842291 -0.12920615  0.31564829 -0.30562454  0.11720937\n",
      "   1.2455138  -0.03675992  0.79638755  0.46343678  0.48664862  0.79203713\n",
      "  -0.26970223 -0.00357199 -0.26764354  0.21760517 -1.32402718 -0.73868537\n",
      "   0.57935286 -0.07551345 -0.42726731  0.72100568 -0.36349025 -0.16353694\n",
      "   0.65941042 -0.78670287  0.1150678  -0.15335704]]\n"
     ]
    }
   ],
   "source": [
    "var = params['Wxi'].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(var,cmap='Greys')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
