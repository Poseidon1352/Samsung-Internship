{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import os\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "seq_length = 1\n",
    "merge_factor = 1#temporal resolution = merge_factor/16000 #discrimination_window = merge_factor*seq_length/16000\n",
    "n_train = 1600000; n_test = 160000;\n",
    "num_channels = 2\n",
    "input_size = num_channels #n_channels*merge_factor\n",
    "num_classes = 2 #n_directions\n",
    "x = tf.placeholder(tf.float32, [None,seq_length, input_size])\n",
    "labels = tf.placeholder(tf.int32, [None])\n",
    "offset = 64\n",
    "train_x = []; train_t = []\n",
    "test_x = []; test_t = []\n",
    "for i in range(num_classes):\n",
    "    temp_data = scipy.io.wavfile.read('noise3/'+'d'+str(0+(180*i))+'.wav')[1][:,::3]\n",
    "    for j in range(n_train+n_test):\n",
    "        vec = np.array(temp_data[offset+(j*seq_length*merge_factor):offset+((j+1)*seq_length*merge_factor)])\n",
    "        vec = vec.reshape(seq_length,merge_factor,2)\n",
    "        vec = np.mean(vec,axis=1)\n",
    "        if j%(11) != 5:\n",
    "            train_x.append(vec)\n",
    "            train_t.append(i)\n",
    "    #for j in range(n_train,n_train+n_test):\n",
    "        else:\n",
    "            test_x.append(vec)\n",
    "            test_t.append(i)\n",
    "\n",
    "train_x = np.array(train_x); train_t = np.array(train_t)\n",
    "train_x = train_x.reshape(n_train*num_classes,seq_length,input_size)\n",
    "test_x = np.array(test_x); test_t = np.array(test_t)\n",
    "test_x = test_x.reshape(n_test*num_classes,seq_length,input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 4, 2)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "hidden_size = 100\n",
    "learning_rate = tf.placeholder(tf.float32,[])\n",
    "lambda_ = tf.placeholder(tf.float32,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "# r_i = np.sqrt(6.0/(input_size + context_size))\n",
    "# r_c = np.sqrt(6.0/(context_size + context_size))\n",
    "# r_y = np.sqrt(6.0/(context_size + num_classes))\n",
    "params = {\n",
    "    'Wxh': tf.Variable(tf.random_normal([input_size, hidden_size],stddev=0.01)),\n",
    "    'Whh': tf.Variable(tf.random_normal([hidden_size, hidden_size],stddev = 0.01)),\n",
    "    'Why': tf.Variable(tf.random_normal([hidden_size,num_classes],stddev = 0.01)),\n",
    "    'bh': tf.Variable(tf.zeros([hidden_size])),\n",
    "    'by': tf.Variable(tf.zeros([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# architecture\n",
    "def RNN(x,params):\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    h = tf.zeros([batch_size,hidden_size])\n",
    "    for t in range(seq_length):\n",
    "        h = tf.tanh(tf.add(tf.add(tf.matmul(x[:,t,:],params['Wxh']),tf.matmul(h,params['Whh'])),params['bh']))\n",
    "    y = tf.add(tf.matmul(h,params['Why']),params['by'])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training strategy\n",
    "y = RNN(x,params)\n",
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y,labels))# + lambda_*(tf.reduce_sum(tf.mul(params['Wxh'],params['Wxh'])) + tf.reduce_sum(tf.mul(params['Whh'],params['Whh'])) + tf.reduce_sum(tf.mul(params['Why'],params['Why'])))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(cost)\n",
    "capped_grads_and_vars = [(tf.clip_by_value(gv[0],-1.,1.), gv[1]) for gv in grads_and_vars]\n",
    "capped_optimizer = optimizer.apply_gradients(capped_grads_and_vars)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0 cost:13.4213\n",
      "train pf = 0.532\n",
      "test pf = 0.515\n",
      "\n",
      "iter100 cost:2.07021\n",
      "train pf = 0.57\n",
      "test pf = 0.565\n",
      "\n",
      "iter200 cost:1.69743\n",
      "train pf = 0.566\n",
      "test pf = 0.515\n",
      "\n",
      "iter300 cost:1.59906\n",
      "train pf = 0.564\n",
      "test pf = 0.495\n",
      "\n",
      "iter400 cost:1.5268\n",
      "train pf = 0.5645\n",
      "test pf = 0.495\n",
      "\n",
      "iter500 cost:1.46137\n",
      "train pf = 0.574\n",
      "test pf = 0.515\n",
      "\n",
      "iter600 cost:1.40044\n",
      "train pf = 0.5685\n",
      "test pf = 0.515\n",
      "\n",
      "iter700 cost:1.34294\n",
      "train pf = 0.57\n",
      "test pf = 0.52\n",
      "\n",
      "iter800 cost:1.28811\n",
      "train pf = 0.57\n",
      "test pf = 0.51\n",
      "\n",
      "iter900 cost:1.23541\n",
      "train pf = 0.573\n",
      "test pf = 0.515\n",
      "\n",
      "iter1000 cost:1.18454\n",
      "train pf = 0.575\n",
      "test pf = 0.515\n",
      "\n",
      "iter1100 cost:1.13542\n",
      "train pf = 0.575\n",
      "test pf = 0.52\n",
      "\n",
      "iter1200 cost:1.08828\n",
      "train pf = 0.575\n",
      "test pf = 0.52\n",
      "\n",
      "iter1300 cost:1.04352\n",
      "train pf = 0.575\n",
      "test pf = 0.52\n",
      "\n",
      "iter1400 cost:1.0014\n",
      "train pf = 0.571\n",
      "test pf = 0.5\n",
      "\n",
      "iter1500 cost:0.961992\n",
      "train pf = 0.574\n",
      "test pf = 0.515\n",
      "\n",
      "iter1600 cost:0.925455\n",
      "train pf = 0.577\n",
      "test pf = 0.52\n",
      "\n",
      "iter1700 cost:0.892162\n",
      "train pf = 0.5775\n",
      "test pf = 0.52\n",
      "\n",
      "iter1800 cost:0.862394\n",
      "train pf = 0.572\n",
      "test pf = 0.51\n",
      "\n",
      "iter1900 cost:0.836333\n",
      "train pf = 0.5715\n",
      "test pf = 0.51\n",
      "\n",
      "iter2000 cost:0.814624\n",
      "train pf = 0.5755\n",
      "test pf = 0.505\n",
      "\n",
      "iter2100 cost:0.79793\n",
      "train pf = 0.569\n",
      "test pf = 0.5\n",
      "\n",
      "iter2200 cost:0.785431\n",
      "train pf = 0.569\n",
      "test pf = 0.5\n",
      "\n",
      "iter2300 cost:0.776032\n",
      "train pf = 0.5665\n",
      "test pf = 0.515\n",
      "\n",
      "iter2400 cost:0.821065\n",
      "train pf = 0.535\n",
      "test pf = 0.46\n",
      "\n",
      "iter2500 cost:0.821641\n",
      "train pf = 0.5305\n",
      "test pf = 0.465\n",
      "\n",
      "iter2600 cost:0.821743\n",
      "train pf = 0.53\n",
      "test pf = 0.475\n",
      "\n",
      "iter2700 cost:0.821555\n",
      "train pf = 0.532\n",
      "test pf = 0.495\n",
      "\n",
      "iter2800 cost:0.821276\n",
      "train pf = 0.5295\n",
      "test pf = 0.495\n",
      "\n",
      "iter2900 cost:0.821043\n",
      "train pf = 0.5215\n",
      "test pf = 0.49\n",
      "\n",
      "iter3000 cost:0.820956\n",
      "train pf = 0.5245\n",
      "test pf = 0.495\n",
      "\n",
      "iter3100 cost:0.821086\n",
      "train pf = 0.5245\n",
      "test pf = 0.495\n",
      "\n",
      "iter3200 cost:0.821474\n",
      "train pf = 0.5245\n",
      "test pf = 0.495\n",
      "\n",
      "iter3300 cost:0.822126\n",
      "train pf = 0.525\n",
      "test pf = 0.5\n",
      "\n",
      "iter3400 cost:0.823017\n",
      "train pf = 0.525\n",
      "test pf = 0.5\n",
      "\n",
      "iter3500 cost:0.824092\n",
      "train pf = 0.5245\n",
      "test pf = 0.505\n",
      "\n",
      "iter3600 cost:0.825278\n",
      "train pf = 0.5245\n",
      "test pf = 0.505\n",
      "\n",
      "iter3700 cost:0.826514\n",
      "train pf = 0.5205\n",
      "test pf = 0.485\n",
      "\n",
      "iter3800 cost:0.827742\n",
      "train pf = 0.5205\n",
      "test pf = 0.485\n",
      "\n",
      "iter3900 cost:0.828928\n",
      "train pf = 0.5205\n",
      "test pf = 0.485\n",
      "\n",
      "iter4000 cost:0.83005\n",
      "train pf = 0.519\n",
      "test pf = 0.485\n",
      "\n",
      "iter4100 cost:0.831099\n",
      "train pf = 0.519\n",
      "test pf = 0.485\n",
      "\n",
      "iter4200 cost:0.832074\n",
      "train pf = 0.518\n",
      "test pf = 0.49\n",
      "\n",
      "iter4300 cost:0.832981\n",
      "train pf = 0.518\n",
      "test pf = 0.49\n",
      "\n",
      "iter4400 cost:0.833821\n",
      "train pf = 0.518\n",
      "test pf = 0.49\n",
      "\n",
      "iter4500 cost:0.834603\n",
      "train pf = 0.518\n",
      "test pf = 0.495\n",
      "\n",
      "iter4600 cost:0.835334\n",
      "train pf = 0.518\n",
      "test pf = 0.495\n",
      "\n",
      "iter4700 cost:0.836018\n",
      "train pf = 0.518\n",
      "test pf = 0.495\n",
      "\n",
      "iter4800 cost:0.83666\n",
      "train pf = 0.518\n",
      "test pf = 0.495\n",
      "\n",
      "iter4900 cost:0.837267\n",
      "train pf = 0.518\n",
      "test pf = 0.495\n",
      "\n",
      "iter5000 cost:0.837841\n",
      "train pf = 0.518\n",
      "test pf = 0.495\n",
      "\n",
      "iter5100 cost:0.838387\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter5200 cost:0.838906\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter5300 cost:0.839402\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter5400 cost:0.839878\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter5500 cost:0.840332\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter5600 cost:0.840769\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter5700 cost:0.841188\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter5800 cost:0.841592\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter5900 cost:0.841979\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter6000 cost:0.84235\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter6100 cost:0.842707\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter6200 cost:0.843049\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter6300 cost:0.843375\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter6400 cost:0.843688\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter6500 cost:0.843985\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter6600 cost:0.844269\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter6700 cost:0.844539\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter6800 cost:0.844796\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter6900 cost:0.845038\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter7000 cost:0.845267\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter7100 cost:0.845484\n",
      "train pf = 0.5175\n",
      "test pf = 0.49\n",
      "\n",
      "iter7200 cost:0.845688\n",
      "train pf = 0.516\n",
      "test pf = 0.49\n",
      "\n",
      "iter7300 cost:0.84588\n",
      "train pf = 0.516\n",
      "test pf = 0.49\n",
      "\n",
      "iter7400 cost:0.846059\n",
      "train pf = 0.5165\n",
      "test pf = 0.49\n",
      "\n",
      "iter7500 cost:0.846226\n",
      "train pf = 0.5165\n",
      "test pf = 0.49\n",
      "\n",
      "iter7600 cost:0.846384\n",
      "train pf = 0.5165\n",
      "test pf = 0.49\n",
      "\n",
      "iter7700 cost:0.84653\n",
      "train pf = 0.5165\n",
      "test pf = 0.49\n",
      "\n",
      "iter7800 cost:0.846666\n",
      "train pf = 0.5165\n",
      "test pf = 0.49\n",
      "\n",
      "iter7900 cost:0.846791\n",
      "train pf = 0.5165\n",
      "test pf = 0.49\n",
      "\n",
      "iter8000 cost:0.846907\n",
      "train pf = 0.5165\n",
      "test pf = 0.49\n",
      "\n",
      "iter8100 cost:0.847014\n",
      "train pf = 0.5165\n",
      "test pf = 0.49\n",
      "\n",
      "iter8200 cost:0.847112\n",
      "train pf = 0.5165\n",
      "test pf = 0.49\n",
      "\n",
      "iter8300 cost:0.847202\n",
      "train pf = 0.5165\n",
      "test pf = 0.49\n",
      "\n",
      "iter8400 cost:0.847284\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter8500 cost:0.847358\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter8600 cost:0.847426\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter8700 cost:0.847486\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter8800 cost:0.84754\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter8900 cost:0.847587\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter9000 cost:0.847629\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter9100 cost:0.847665\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter9200 cost:0.847696\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter9300 cost:0.847721\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter9400 cost:0.847743\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter9500 cost:0.84776\n",
      "train pf = 0.5135\n",
      "test pf = 0.49\n",
      "\n",
      "iter9600 cost:0.847772\n",
      "train pf = 0.513\n",
      "test pf = 0.48\n",
      "\n",
      "iter9700 cost:0.84778\n",
      "train pf = 0.513\n",
      "test pf = 0.48\n",
      "\n",
      "iter9800 cost:0.847786\n",
      "train pf = 0.513\n",
      "test pf = 0.48\n",
      "\n",
      "iter9900 cost:0.847787\n",
      "train pf = 0.513\n",
      "test pf = 0.48\n",
      "\n",
      "iter10000 cost:0.847785\n",
      "train pf = 0.5155\n",
      "test pf = 0.485\n",
      "\n",
      "iter10100 cost:0.84778\n",
      "train pf = 0.5155\n",
      "test pf = 0.485\n",
      "\n",
      "iter10200 cost:0.847771\n",
      "train pf = 0.5155\n",
      "test pf = 0.485\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-289-c3e032302253>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcapped_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iter'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' cost:'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 372\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    373\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 636\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 708\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    709\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    713\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "while True:\n",
    "    _,cost_ = sess.run([capped_optimizer,cost],feed_dict={x:train_x,labels:train_t,learning_rate:0.1,lambda_:0.0})\n",
    "    if n_iter % 100 == 0:\n",
    "        print('iter'+str(n_iter)+' cost:'+str(cost_))\n",
    "        y_train = sess.run(y,feed_dict={x:train_x})\n",
    "        print 'train pf = ' + str((sum(np.argmax(y_train,axis=1) == train_t) + 0.0)/(n_train*num_classes))\n",
    "        y_test = sess.run(y,feed_dict={x:test_x})\n",
    "        print 'test pf = ' + str((sum(np.argmax(y_test,axis=1) == test_t) + 0.0)/(n_test*num_classes))+'\\n'\n",
    "#         mypath = 'vars/iter'+str(n_iter)\n",
    "#         if not os.path.isdir(mypath):\n",
    "#            os.makedirs(mypath)\n",
    "#         myfile = mypath+'/'+str(n_iter)\n",
    "#         saver.save(sess,myfile,write_meta_graph=False)\n",
    "    n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
