{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "#%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display import clear_output\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Preprocessing\n",
    "* d0.wav and d1.wav contain sound produced by the footsteps of two distinct people.\n",
    "* Preprocessed using audacity to remove silence.\n",
    "    * Galaxy S7 Edge, default recorder, high quality, mono.\n",
    "    * Audacity settings:\n",
    "        * Minimum silence: 1ms\n",
    "        * Maximum silence: 5000ms\n",
    "        * Compression ratio: 1000:1\n",
    "        * Siulence level: -45dB\n",
    "* Imported and converted to MFCC vectors using suitable fixed window. Tune window parameters for better performance.\n",
    "* Concatenated into one training vector.\n",
    "* Standardized to $ \\mu = 0, \\sigma = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "train_x = np.concatenate((mnist.train.images[mnist.train.labels == 0],mnist.train.images[mnist.train.labels == 1]))\n",
    "# train_x = np.array(train_x); mu = np.mean(train_x); sigma = np.std(train_x); #data standardization\n",
    "# train_x = (train_x - mu + 0.0)/sigma\n",
    "\n",
    "num_classes = 2;\n",
    "n_train = train_x.shape[0]\n",
    "n0 = np.sum(mnist.train.labels == 0)\n",
    "input_size = train_x.shape[1]\n",
    "x = tf.placeholder(tf.float32, [None, input_size])\n",
    "momentum = tf.placeholder(tf.float32,[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters\n",
    "* Adjust hidden_shape to add layers or neurons within the layers. Eg: [100,2,100] <=> 3 hidden layers with 100,2,100 neurons in the 1st,2nd,3rd layer respectively.\n",
    "* Edit act_fns, code_lyr according to hidden_shape. Here the sparse representation is hidden layer no 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_shape = [50,2,50] #No of neurons in each hidden layer\n",
    "act_fns = ['tanh','tanh','tanh'] #Activation functions of layers\n",
    "code_lyr = 2 #index of hidden layer containing sparse vector\n",
    "num_lyr = len(hidden_shape) #No of hidden layers\n",
    "net_shape = [input_size] + hidden_shape + [input_size]\n",
    "learning_rate = tf.placeholder(tf.float32,[])\n",
    "beta = tf.placeholder(tf.float32,[]) #sparsity_penalty weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "params = {'W':{},'b':{}} #W: Weights, b: biases\n",
    "for lay_num in range(num_lyr+1):\n",
    "    params['W'][lay_num] = tf.Variable(tf.random_normal([net_shape[lay_num], net_shape[lay_num+1]],stddev = 0.1),name='weights_layer'+str(lay_num))\n",
    "    params['b'][lay_num] = tf.Variable(tf.random_normal([net_shape[lay_num+1]],stddev = 0.1),name='biases_layer'+str(lay_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Network Graph\n",
    "* Cost = Recontruction error + beta*Sparsity penalty\n",
    "* Recontruction error is the L2 norm between the input and output (reconstructed) vector. This is usual for continuous input autoencoders\n",
    "* The sparsity penalty is nonstandard. It is applied on the \"sparse\" 2-vector. Since it is output from a sigmoid layer, it lies in unit square centered at (0.5,0.5). A decreasing function of the distance from the line y=x is used. This ensures minima that are furthest apart in 2D space [At (1,0) and (0,1)]. Modify this function according to the output space of the 2-vector layer.\n",
    "* The intuition behind the setup is that if the input contains MFCCs from two distinct people (i.e feature values from distinct classes), they should settle at the two distinct minima. This is because settling farther away from each other allows greater freedom in representational power for reconstruction. \n",
    "* This also allows use to deterministically say where the clusters will converge. One class should converge above the line y = x and another, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#network graph\n",
    "def act_fn(a,lay_num):\n",
    "    if act_fns[lay_num] == 'tanh':\n",
    "        return tf.tanh(a)\n",
    "    elif act_fns[lay_num] == 'relu':\n",
    "        return tf.nn.relu(a)\n",
    "    elif act_fns[lay_num] == 'elu':\n",
    "        return tf.nn.elu(a)\n",
    "    elif act_fns[lay_num] == 'sig':\n",
    "        return tf.sigmoid(a)\n",
    "    \n",
    "def AutoEncoder(x,params):\n",
    "    z = x\n",
    "    for lay_num in range(num_lyr):\n",
    "        z = act_fn(tf.add(tf.matmul(z,params['W'][lay_num]),params['b'][lay_num]),lay_num)\n",
    "        if lay_num == code_lyr-1:\n",
    "            corner_pusher = -tf.reduce_mean(tf.abs(tf.sub(z[:,0],z[:,1])))/np.sqrt(2) #distance from line y = x\n",
    "            sparsity_penalty = corner_pusher\n",
    "            code = z\n",
    "    x_ = tf.add(tf.matmul(z,params['W'][lay_num+1]),params['b'][lay_num+1])\n",
    "    cost = tf.sqrt(tf.reduce_mean(tf.squared_difference(x,x_))) #+ tf.mul(beta,sparsity_penalty)\n",
    "    return (cost,code,x_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph Construction\n",
    "* Ordinary gradient descent optimization is used. Other optimizers may be considered to automate the learning process better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost,code,x_ = AutoEncoder(x,params)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "save_vars = {}\n",
    "for lay_num in range(num_lyr):\n",
    "    save_vars['weights_layer'+str(lay_num)] = params['W'][lay_num]\n",
    "    save_vars['biases_layer'+str(lay_num)] = params['b'][lay_num]\n",
    "saver = tf.train.Saver(save_vars)\n",
    "restore_vars = {}\n",
    "if num_lyr > 1:\n",
    "    for lay_num in range(num_lyr-1):\n",
    "        restore_vars['weights_layer'+str(lay_num)] = params['W'][lay_num]\n",
    "        restore_vars['biases_layer'+str(lay_num)] = params['b'][lay_num]\n",
    "    restorer = tf.train.Saver(restore_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameter initialization\n",
    "sess.run(tf.initialize_all_variables())\n",
    "if num_lyr > 1:\n",
    "    restorer.restore(sess,'saved_vars')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning\n",
    "* The model should have sufficient representational power:\n",
    "    * The size of the sparse vector should scale with the number of clusters (and hence classes) we want to detect. Here num_classes = 2. Size(sparse vector) = 2 proved to be sufficient.\n",
    "    * Set beta = 0 and adjust the size of other layers until the reconstruction error is low.\n",
    "* Beta should be small enough that it doesn't substantitally affect the recontructive capability but still pushes the points to the desired peripheries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0 cost:0.19651\n",
      "iter10 cost:0.196186\n",
      "iter20 cost:0.195896\n",
      "iter30 cost:0.195637\n",
      "iter40 cost:0.195406\n",
      "iter50 cost:0.195203\n",
      "iter60 cost:0.195024\n",
      "iter70 cost:0.194867\n",
      "iter80 cost:0.194729\n",
      "iter90 cost:0.194609\n",
      "iter100 cost:0.194503\n",
      "iter110 cost:0.194411\n",
      "iter120 cost:0.194329\n",
      "iter130 cost:0.194257\n",
      "iter140 cost:0.194193\n",
      "iter150 cost:0.194137\n",
      "iter160 cost:0.194086\n",
      "iter170 cost:0.19404\n",
      "iter180 cost:0.193998\n",
      "iter190 cost:0.193959\n",
      "iter200 cost:0.193923\n",
      "iter210 cost:0.19389\n",
      "iter220 cost:0.193859\n",
      "iter230 cost:0.193829\n",
      "iter240 cost:0.1938\n",
      "iter250 cost:0.193773\n",
      "iter260 cost:0.193745\n",
      "iter270 cost:0.193718\n",
      "iter280 cost:0.193692\n",
      "iter290 cost:0.193665\n",
      "iter300 cost:0.193638\n",
      "iter310 cost:0.193612\n",
      "iter320 cost:0.193584\n",
      "iter330 cost:0.193556\n",
      "iter340 cost:0.193528\n",
      "iter350 cost:0.193498\n",
      "iter360 cost:0.193468\n",
      "iter370 cost:0.193436\n",
      "iter380 cost:0.193404\n",
      "iter390 cost:0.193369\n",
      "iter400 cost:0.193334\n",
      "iter410 cost:0.193297\n",
      "iter420 cost:0.193259\n",
      "iter430 cost:0.193218\n"
     ]
    }
   ],
   "source": [
    "#learning\n",
    "n_iter = 0\n",
    "while True:\n",
    "    try:\n",
    "        _,cost_,code_,x__ = sess.run([optimizer,cost,code,x_],feed_dict={x:train_x,learning_rate:3.0,beta:1.0})\n",
    "        if n_iter % 10 == 0:\n",
    "            print('iter'+str(n_iter)+' cost:'+str(cost_))\n",
    "        if n_iter+1 % 20 == 0:\n",
    "            clear_output()\n",
    "        n_iter += 1\n",
    "    except KeyboardInterrupt:\n",
    "        saver.save(sess,'saved_vars')\n",
    "        print \"Training is stopped\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restore_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.max(code_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plots\n",
    "plt.title('Sparse Vectors'); plt.xlabel('Dimension 1'); plt.ylabel('Dimension 2');\n",
    "plt.scatter(code_[:n0][:,0],code_[:n0][:,1],c=[1,0,0], label = 'Person 1')\n",
    "plt.scatter(code_[n0:][:,0],code_[n0:][:,1],c=[0,0,1], label = 'Person 2')\n",
    "plt.legend()\n",
    "plt.plot([-1,1],[-1,1],c=[0,0,0],linewidth=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "np.sum((code_[n0:,0] < code_[n0:,1])+0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum((code_[:n0,0] > code_[:n0,1])+0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1 = train_x[1000].reshape(28,28)\n",
    "plt.imshow(img1,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# img2 = (x__[1100]*sigma + mu).reshape(28,28)\n",
    "img2 = x__[6000].reshape(28,28)\n",
    "plt.imshow(img2,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
