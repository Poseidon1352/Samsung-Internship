{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "#%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.display import clear_output\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "train_x = np.concatenate((mnist.train.images[mnist.train.labels == 0],mnist.train.images[mnist.train.labels == 1]))\n",
    "# train_x = np.array(train_x); mu = np.mean(train_x); sigma = np.std(train_x); #data standardization\n",
    "# train_x = (train_x - mu + 0.0)/sigma\n",
    "\n",
    "num_classes = 2;\n",
    "n_train = train_x.shape[0]\n",
    "n0 = np.sum(mnist.train.labels == 0)\n",
    "input_size = train_x.shape[1]\n",
    "x = tf.placeholder(tf.float32, [None, input_size])\n",
    "momentum = tf.placeholder(tf.float32,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_shape = [50,2,50] #No of neurons in each hidden layer\n",
    "act_fns = ['tanh','tanh','tanh'] #Activation functions of layers\n",
    "code_lyr = 2 #index of hidden layer containing sparse vector\n",
    "num_lyr = len(hidden_shape) #No of hidden layers\n",
    "net_shape = [input_size] + hidden_shape + [input_size]\n",
    "learning_rate = tf.placeholder(tf.float32,[])\n",
    "beta = tf.placeholder(tf.float32,[]) #sparsity_penalty weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "params = {'W':{},'b':{}} #W: Weights, b: biases\n",
    "for lay_num in range(num_lyr+1):\n",
    "    params['W'][lay_num] = tf.Variable(tf.random_normal([net_shape[lay_num], net_shape[lay_num+1]],stddev = 0.05),name='weights_layer'+str(lay_num))\n",
    "    params['b'][lay_num] = tf.Variable(tf.random_normal([net_shape[lay_num+1]],stddev = 0.05),name='biases_layer'+str(lay_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#network graph\n",
    "def act_fn(a,lay_num):\n",
    "    if act_fns[lay_num] == 'tanh':\n",
    "        return tf.tanh(a)\n",
    "    elif act_fns[lay_num] == 'relu':\n",
    "        return tf.nn.relu(a)\n",
    "    elif act_fns[lay_num] == 'elu':\n",
    "        return tf.nn.elu(a)\n",
    "    elif act_fns[lay_num] == 'sig':\n",
    "        return tf.sigmoid(a)\n",
    "    \n",
    "def AutoEncoder(x,params):\n",
    "    z = x\n",
    "    for lay_num in range(num_lyr):\n",
    "        z = act_fn(tf.add(tf.matmul(z,params['W'][lay_num]),params['b'][lay_num]),lay_num)\n",
    "        if lay_num == code_lyr-1:\n",
    "            corner_pusher = -tf.reduce_mean(tf.abs(tf.sub(z[:,0],z[:,1])))/np.sqrt(2) #distance from line y = x\n",
    "            sparsity_penalty = corner_pusher\n",
    "            code = z\n",
    "    x_ = tf.add(tf.matmul(z,params['W'][lay_num+1]),params['b'][lay_num+1])\n",
    "    cost = tf.sqrt(tf.reduce_mean(tf.squared_difference(x,x_))) + tf.mul(beta,sparsity_penalty)\n",
    "    return (cost,code,x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost,code,x_ = AutoEncoder(x,params)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#parameter initialization\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0 cost:-0.493383\n",
      "iter10 cost:-1.19852\n",
      "iter20 cost:-1.20031\n",
      "iter30 cost:-1.20068\n",
      "iter40 cost:-1.20087\n",
      "iter50 cost:-1.201\n",
      "iter60 cost:-1.20109\n",
      "iter70 cost:-1.20116\n",
      "iter80 cost:-1.20121\n",
      "iter90 cost:-1.20126\n",
      "iter100 cost:-1.20129\n",
      "iter110 cost:-1.20133\n",
      "iter120 cost:-1.20135\n",
      "iter130 cost:-1.20138\n",
      "iter140 cost:-1.2014\n",
      "Training is stopped\n"
     ]
    }
   ],
   "source": [
    "#learning\n",
    "n_iter = 0\n",
    "while True:\n",
    "    try:\n",
    "        _,cost_,code_,x__ = sess.run([optimizer,cost,code,x_],feed_dict={x:train_x,learning_rate:3.0,beta:1.0})\n",
    "        if n_iter % 10 == 0:\n",
    "            print('iter'+str(n_iter)+' cost:'+str(cost_))\n",
    "        if n_iter+1 % 20 == 0:\n",
    "            clear_output()\n",
    "        n_iter += 1\n",
    "    except KeyboardInterrupt:\n",
    "        print \"Training is stopped\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(code_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plots\n",
    "plt.title('Sparse Vectors'); plt.xlabel('Dimension 1'); plt.ylabel('Dimension 2');\n",
    "plt.scatter(code_[n0:][:,0],code_[n0:][:,1],c=[0,0,1], label = 'Person 2')\n",
    "plt.scatter(code_[:n0][:,0],code_[:n0][:,1],c=[1,0,0], label = 'Person 1')\n",
    "plt.legend()\n",
    "plt.plot([-1,1],[-1,1],c=[0,0,0],linewidth=2.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6123.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf)\n",
    "np.sum((code_[n0:,0] < code_[n0:,1])+0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5433.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((code_[:n0,0] > code_[:n0,1])+0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1 = train_x[1000].reshape(28,28)\n",
    "plt.imshow(img1,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# img2 = (x__[1100]*sigma + mu).reshape(28,28)\n",
    "img2 = x__[10000].reshape(28,28)\n",
    "plt.imshow(img2,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6179"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_.shape[0] - n0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
