{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fact = 2\n",
    "seq_length = 5\n",
    "hidden_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cast(string):\n",
    "    if string == '':\n",
    "        return 0\n",
    "    else:\n",
    "        return float(string)\n",
    "\n",
    "X = open('lights.txt', 'r').read().splitlines()\n",
    "X = [x.split(',') for x in X]\n",
    "X = [[cast(a) for a in x] for x in X]\n",
    "factors = np.array([x[:n_fact] for x in X])\n",
    "lights = np.array([x[n_fact:] for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = tf.placeholder(tf.float32, [None, seq_length])\n",
    "f = tf.placeholder(tf.float32, [None, n_fact])\n",
    "learning_rate = tf.placeholder(tf.float32,[])\n",
    "params = {\n",
    "    'Wxh': tf.Variable(tf.random_normal([1, hidden_size],stddev=0.01)),\n",
    "    'Wfh': tf.Variable(tf.random_normal([n_fact, hidden_size],stddev=0.01)),\n",
    "    'Whh': tf.Variable(tf.random_normal([hidden_size, hidden_size],stddev = 0.01)),\n",
    "    'Why': tf.Variable(tf.random_normal([hidden_size,1],stddev = 0.01)),\n",
    "    'bh': tf.Variable(tf.zeros([hidden_size])),\n",
    "    'by': tf.Variable(tf.zeros([1]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x_t,f,params):\n",
    "    batch_size = tf.shape(x_t)[0]\n",
    "    h = tf.zeros([batch_size,hidden_size])\n",
    "    y = x_t\n",
    "    for t in range(1,seq_length):\n",
    "        h = tf.tanh(tf.add(tf.add(tf.add(tf.matmul(x_t,params['Wxh']),tf.matmul(f,params['Wfh'])),tf.matmul(h,params['Whh'])),params['bh']))\n",
    "        x_t = tf.add(tf.matmul(h,params['Why']),params['by'])\n",
    "        y = tf.concat(1,[y,x_t])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = RNN(l[:,0:1],f,params)\n",
    "loss = tf.reduce_sum(tf.squared_difference(y,l))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_grads_and_vars = [(tf.clip_by_value(gv[0],-1.,1.), gv[1]) for gv in grads_and_vars]\n",
    "capped_optimizer = optimizer.apply_gradients(capped_grads_and_vars)\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.0, -0.0, -0.0, -0.0, -0.0], [5.0, -0.0, 0.0, 0.0, 0.0], [5.0, -0.0, 0.0, 0.0, 0.0], [5.0, -0.0, 0.0, 0.0, 0.0]]\n",
      "iter0 loss:88.0194\n",
      "[[5.0, 3.0, 2.0, 1.0, 1.0], [5.0, 3.0, 2.0, 1.0, 1.0], [5.0, 3.0, 1.0, 1.0, 0.0], [5.0, 3.0, 1.0, 1.0, 0.0]]\n",
      "iter100 loss:40.9985\n",
      "[[5.0, 3.0, 1.0, 2.0, 1.0], [5.0, 3.0, 1.0, 2.0, 1.0], [5.0, 3.0, 0.0, 1.0, -0.0], [5.0, 2.0, -0.0, 0.0, -1.0]]\n",
      "iter200 loss:29.1401\n",
      "[[5.0, 4.0, 1.0, 3.0, 1.0], [5.0, 3.0, 1.0, 3.0, 1.0], [5.0, 3.0, 0.0, 2.0, -1.0], [5.0, 2.0, -0.0, 1.0, -1.0]]\n",
      "iter300 loss:24.7153\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 3.0, 0.0], [5.0, 3.0, 0.0, 1.0, -1.0], [5.0, 2.0, 0.0, 0.0, -1.0]]\n",
      "iter400 loss:21.2759\n",
      "[[5.0, 4.0, 1.0, 4.0, -0.0], [5.0, 3.0, 1.0, 3.0, 0.0], [5.0, 3.0, 0.0, 1.0, -1.0], [5.0, 2.0, 0.0, -0.0, -0.0]]\n",
      "iter500 loss:19.3993\n",
      "[[5.0, 4.0, 1.0, 4.0, -0.0], [5.0, 3.0, 1.0, 3.0, 0.0], [5.0, 3.0, 0.0, 1.0, -1.0], [5.0, 2.0, 0.0, -0.0, 0.0]]\n",
      "iter600 loss:17.6815\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 3.0, 0.0], [5.0, 3.0, 0.0, 1.0, -0.0], [5.0, 2.0, -0.0, -0.0, 0.0]]\n",
      "iter700 loss:14.5126\n",
      "[[5.0, 5.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 4.0, 0.0, 0.0, -0.0], [5.0, 1.0, -0.0, -0.0, 0.0]]\n",
      "iter800 loss:11.1628\n",
      "[[5.0, 5.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 4.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter900 loss:9.52081\n",
      "[[5.0, 5.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 4.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter1000 loss:9.04497\n",
      "[[5.0, 5.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 4.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter1100 loss:8.88368\n",
      "[[5.0, 5.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 4.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter1200 loss:8.77207\n",
      "[[5.0, 5.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter1300 loss:8.66182\n",
      "[[5.0, 5.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter1400 loss:8.5395\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter1500 loss:8.39692\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter1600 loss:8.2272\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter1700 loss:8.02263\n",
      "[[5.0, 4.0, 1.0, 4.0, -0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter1800 loss:7.77765\n",
      "[[5.0, 4.0, 1.0, 4.0, -0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter1900 loss:7.49136\n",
      "[[5.0, 4.0, 1.0, 4.0, -0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter2000 loss:7.16611\n",
      "[[5.0, 4.0, 1.0, 4.0, -0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, -0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter2100 loss:6.81014\n",
      "[[5.0, 4.0, 1.0, 4.0, -0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter2200 loss:6.43294\n",
      "[[5.0, 4.0, 1.0, 4.0, -0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter2300 loss:6.04123\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter2400 loss:5.64054\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter2500 loss:5.23601\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter2600 loss:4.83282\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter2700 loss:4.4365\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter2800 loss:4.05336\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter2900 loss:3.68763\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter3000 loss:3.34258\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter3100 loss:3.0204\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter3200 loss:2.72213\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter3300 loss:2.44711\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter3400 loss:2.19337\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter3500 loss:1.96121\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 5.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter3600 loss:1.75076\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter3700 loss:1.5625\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter3800 loss:1.39567\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, 0.0], [5.0, 1.0, 0.0, -0.0, 0.0]]\n",
      "iter3900 loss:1.24888\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, 0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter4000 loss:1.12087\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 2.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, 0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter4100 loss:1.00939\n",
      "[[5.0, 4.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, 0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter4200 loss:0.912488\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, 0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter4300 loss:0.827706\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, 0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter4400 loss:0.752563\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter4500 loss:0.685675\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter4600 loss:0.626077\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter4700 loss:0.572864\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter4800 loss:0.525334\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter4900 loss:0.48281\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter5000 loss:0.444686\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter5100 loss:0.410341\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter5200 loss:0.378814\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, -0.0, 0.0]]\n",
      "iter5300 loss:0.349889\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter5400 loss:0.325693\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter5500 loss:0.299551\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter5600 loss:0.275782\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter5700 loss:0.254156\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter5800 loss:0.23451\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter5900 loss:0.216639\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter6000 loss:0.20041\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter6100 loss:0.185662\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter6200 loss:0.172307\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter6300 loss:0.160201\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter6400 loss:0.149206\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter6500 loss:0.139222\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter6600 loss:0.130133\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter6700 loss:0.121888\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter6800 loss:0.114413\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter6900 loss:0.107588\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter7000 loss:0.10131\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter7100 loss:0.095567\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter7200 loss:0.0903298\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter7300 loss:0.0855767\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter7400 loss:0.0812275\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter7500 loss:0.0771958\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter7600 loss:0.0735589\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter7700 loss:0.0701228\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter7800 loss:0.0671893\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter7900 loss:0.0645977\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter8000 loss:0.0622588\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter8100 loss:0.0600725\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter8200 loss:0.058068\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter8300 loss:0.056227\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter8400 loss:0.0545403\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter8500 loss:0.0529455\n",
      "[[5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 3.0, 1.0, 4.0, 0.0], [5.0, 6.0, 0.0, 0.0, -0.0], [5.0, 0.0, 0.0, 0.0, -0.0]]\n",
      "iter8600 loss:0.0514788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception AssertionError: AssertionError(\"Nesting violated for default stack of <type 'weakref'> objects\",) in <bound method InteractiveSession.__del__ of <tensorflow.python.client.session.InteractiveSession object at 0x7f5ecc197b50>> ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-e4befb4d6de3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcapped_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mfactors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0my_proc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 372\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    373\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 636\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    637\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 708\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    709\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    713\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 715\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    716\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    695\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    696\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iter = 0\n",
    "while n_iter < 10000:\n",
    "    _,loss_,y_ = sess.run([capped_optimizer,loss,y],feed_dict={l:lights,f:factors,learning_rate:0.001})\n",
    "    if n_iter % 100 == 0:\n",
    "        y_proc = [[round(a) for a in b] for b in y_]\n",
    "        print y_proc\n",
    "        print('iter'+str(n_iter)+' loss:'+str(loss_))\n",
    "    n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cast(string):\n",
    "    if string == '':\n",
    "        return 0\n",
    "    else:\n",
    "        return float(string)\n",
    "\n",
    "X = open('lights_test.txt', 'r').read().splitlines()\n",
    "X = [x.split(',') for x in X]\n",
    "X = [[cast(a) for a in x] for x in X]\n",
    "batch_size = len(X)\n",
    "factors_test = np.array([x[:n_fact] for x in X])\n",
    "lights_test = np.array([x[n_fact:] for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.          0.07351013  0.03473237  0.03876147 -0.04648024]\n",
      " [ 5.          6.02549601  0.07673359  0.05386394 -0.02784666]]\n"
     ]
    }
   ],
   "source": [
    "y_ = sess.run(y,feed_dict={l:lights_test,f:factors_test})\n",
    "print y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
