{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cast(string):\n",
    "    if string == '':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(string)\n",
    "\n",
    "#Data Input\n",
    "X = open('input.txt', 'r').read().splitlines()\n",
    "X = [x.split(',') for x in X]\n",
    "X = [[cast(a) for a in x] for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "datum_size = len(X[0])\n",
    "n_fact = 3 #no of factors\n",
    "n_nutr = datum_size - n_fact\n",
    "hidden_size = 100 # size of hidden layer of neurons\n",
    "seq_length = len(X) # number of steps to unroll the RNN for\n",
    "learning_rate = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "X_mean = np.nanmean(X,axis=0)\n",
    "X_range = np.nanmax(X,axis=0) - np.nanmin(X,axis=0)\n",
    "X_range[X_range == 0] = 1\n",
    "X = (X - X_mean)/X_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(\"float\", [seq_length, datum_size])\n",
    "params = {\n",
    "    'Wxh': tf.Variable(tf.random_normal([hidden_size, datum_size],stddev=0.01)),\n",
    "    'Whh': tf.Variable(tf.random_normal([hidden_size, hidden_size],stddev = 0.01)),\n",
    "    'Why': tf.Variable(tf.random_normal([n_nutr, hidden_size],stddev = 0.01)),\n",
    "    'bh': tf.Variable(tf.zeros([hidden_size,1])),\n",
    "    'by': tf.Variable(tf.zeros([n_nutr,1]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RNN(x,params):\n",
    "    loss = tf.constant(0.0)\n",
    "    #loss = tf.Print(loss,[loss],'init_loss:')\n",
    "    h = tf.random_normal([hidden_size,1])\n",
    "    x_t = tf.reshape(x[0,:],[datum_size,1])\n",
    "    for t in range(seq_length-1):\n",
    "        h = tf.tanh(tf.add(tf.add(tf.matmul(params['Wxh'],x_t),tf.matmul(params['Whh'],h)),params['bh']))\n",
    "        y = tf.add(tf.matmul(params['Why'],h),params['by'])\n",
    "        def f1(): return tf.reshape(x[t+1,:],[datum_size,1])\n",
    "        def f2(): return tf.concat(0,[tf.reshape(x[t+1,:n_fact],[n_fact,1]),y])\n",
    "        x_nxt = tf.cond(tf.is_nan(x[t+1,n_fact]),f2,f1)\n",
    "        loss = tf.add(loss,0.5*tf.reduce_sum(tf.squared_difference(x_nxt[n_fact:,:],y)))\n",
    "        #loss = tf.Print(loss,[loss],'loss:')\n",
    "        x_t = x_nxt\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_iter = 0\n",
    "sess.run(tf.initialize_all_variables())\n",
    "loss = RNN(x,params)\n",
    "tf.scalar_summary('loss',loss)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_grads_and_vars = [(tf.clip_by_value(gv[0],-1.,1.), gv[1]) for gv in grads_and_vars]\n",
    "capped_optimizer = optimizer.apply_gradients(capped_grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_summary = tf.merge_all_summaries()\n",
    "train_writer = tf.train.SummaryWriter('train_summary/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0 loss:255.946\n",
      "iter100 loss:45.1785\n",
      "iter200 loss:32.446\n",
      "iter300 loss:8.80719\n",
      "iter400 loss:8.68623\n",
      "iter500 loss:5.9733\n",
      "iter600 loss:5.9269\n",
      "iter700 loss:4.71681\n",
      "iter800 loss:4.85979\n",
      "iter900 loss:5.25976\n"
     ]
    }
   ],
   "source": [
    "while n_iter < 1000:\n",
    "    summary,_,cost = sess.run([merged_summary,capped_optimizer,loss],feed_dict={x:X})\n",
    "    train_writer.add_summary(summary,n_iter)\n",
    "    if n_iter % 100 == 0:\n",
    "        print('iter'+str(n_iter)+' loss:'+str(cost))\n",
    "    n_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
